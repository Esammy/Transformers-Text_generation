# Transformers-Text_generation

Transformers is a pretty great tool used in NLP. Here it is used to generate text using whatever input text you give to it as a guide.
In this text generation, GPT-2 (Generative Pre-trained Transformer 2) which was train on a very large text data as a result your answer from the program (bot) might not be totally reliable. For example a question was asked and here is the respond from the pre-trained model:
![Example 3](https://user-images.githubusercontent.com/39604112/168477594-44cd11e7-ccf3-43e3-b3f3-9e2cdd2d556e.JPG)

It can also be reliable is some caseing depending on the problem at hand.
